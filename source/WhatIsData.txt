What is Data (DataONE Perspective)?
===================================

:Author: Initial version by Dave Vieglais <vieglais@ku.edu>

:Status: DRAFT - comments, edits, even complete rewrites welcome and expected


This document describes the concept of "data" within the first iteration of
the DataONE system.


Glossary
--------

:Data: 

  Typically refers to scientific data. Where ambiguity between the science
  data and another form of data, the full term "science data" should be used.  
  DataONE services always return exact copies of the original data as submitted 
  to DataONE.


:Metadata:

  Data describing data. There are currently two distinct forms of metadata
  managed by DataONE, "science metadata" and "system metadata".


:Science Metadata:

  A set of information that describes a science data set. Science metadata
  will typically take the form of a document, generally expressed in a dialect
  of XML.


:System Metadata:

  Information used by DataONE to describe content (science data or science
  metadata) managed by DataONE.


:Data Package:

  The term "Data Package" refers to the combination of all objects
  associated with a data set.  In the simplest case this would be four objects:
  a data object, a science metadata object, and system metdata for each.


:Coordinating Node:

  A DataONE Coordinating Node (commonly referred to as "CN") is a service that
  manages content in the entire DataONE system. There are at least three CNs in
  DataONE, with content replicated across all three (i.e. the CN contents are 
  eventually consistent).  The CNs store all original copies of science metadata
  and provide discovery services to assist users in searching and retrieving 
  content from the system.


:Member Node:

  A DataONE Member Node (MN) is a service that stores data and metadata and may
  store content replicated from other MNs as directed by the CNs.


:Investigator Toolkit:

  The DataONE Investigator Toolkit (ITK) is a set of tools that assist users in
  interacting with the DataONE system.   



Overview
--------

Data in the context of DataONE is a discrete unit of digital content that is
expected to represent information obtained from some experiment or scientific
study. The data is accompanied by "science metadata", which is a separate unit
of digital content that describes properties of the data. Each unit of science
data or science metadata is accompanied by a "system metadata" document which
contains attributes that describe the digital object it accompanies (e.g.
hash, time stamps, ownership, relationships). 

.. figure:: images/d1_data.png
   :width: 3.75in

   Core data elements of DataONE

.. 
  @startuml images/d1_data.png
  
  Object: Identifier: string
  
  ScienceData: 
  
  ScienceMetadata:
  
  SystemMetadata: Created: dateTime
  SystemMetadata: Expires: dateTime
  SystemMetadata: SysMetadataCreated: dateTime
  SystemMetadata: SysMetadataModified: dateTime
  SystemMetadata: ObjectFormat: ObjectFormatType
  SystemMetadata: Size: decimal
  SystemMetadata: Submitter: PrincipalType
  SystemMetadata: RightsHolder: PrincipalType
  SystemMetadata: OriginMemberNode: NodeReferenceType
  SystemMetadata: AuthoritativeMemberNode: NodeReferenceType
  SystemMetadata: Obsoletes: IdentifierType [0..*]
  SystemMetadata: ObsoletedBy: IdentifierType [0..*]
  SystemMetadata: DerivedFrom: IdentifierType [0..*]
  SystemMetadata: Describes: IdentifierType [0..*]
  SystemMetadata: DescribedBy: IdentifierType [0..*]
  SystemMetadata: Replica: ReplicaType [0..*]
  SystemMetadata: Checksum: string
  SystemMetadata: ChecksumAlgorithm: ChecksumAlgorithmType
  SystemMetadata: EmbargoExpires: dateTime [0..1]
  SystemMetadata: AccessRule: AccessRuleType [0..*]
  
  ScienceData --|> Object
  ScienceMetadata --|> Object
  SystemMetadata --|> Object
 
  SystemMetadata -- "1" ScienceMetadata
  SystemMetadata -- "1"  ScienceData

  @enduml


In the initial version of DataONE, science data are treated as opaque sets of bytes
and are stored on Member Nodes (MN). A copy of the science metadata is held
by the Coordinating Nodes (CN) and is parsed to extract attributes that to assist
the discovery process.

This behavior is likely to change in the future to enable processing of the
data with operations such as translation (e.g. for format migration),
extraction (e.g. for rendering), and merging (e.g. to combine multiple
instances of data that are expressed in different formats). Such operations
rely upon a stable, accessible framework supporting reliable data access, and
so are targeted after the initial requirements of DataONE are met and the core
infrastructure is demonstrably robust.


Metadata Types
--------------

The following metadata formats are of interest to the DataONE project for the
initial version and are representative of the types of content that will need
to be stored and parsed.

In all cases the descriptive text was retrieved from the URL provided with the
description. Hence, look at the documentation provided at the URL for
authoritative descriptions of the particular standard.



Dublin Core
~~~~~~~~~~~

- http://dublincore.org/documents/dces/

The Dublin Core Metadata Element Set is a vocabulary of fifteen properties for
use in resource description.



Darwin Core
~~~~~~~~~~~

- http://rs.tdwg.org/dwc/index.htm 

The Darwin Core is body of standards. It includes a glossary of terms (in
other contexts these might be called properties, elements, fields, columns,
attributes, or concepts) intended to facilitate the sharing of information
about biological diversity by providing reference definitions, examples, and
commentaries. The Darwin Core is primarily based on taxa, their occurrence in
nature as documented by observations, specimens, and samples, and related
information. Included are documents describing how these terms are managed,
how the set of terms can be extended for new purposes, and how the terms can
be used. The Simple Darwin Core [SIMPLEDWC] is a specification for one
particular way to use the terms - to share data about taxa and their
occurrences in a simply structured way - and is probably what is meant if
someone suggests to "format your data according to the Darwin Core".



EML
~~~

- http://knb.ecoinformatics.org/software/eml

Ecological Metadata Language (EML) is a metadata specification developed by
the ecology discipline and for the ecology discipline. It is based on prior
work done by the Ecological Society of America and associated efforts
(Michener et al., 1997, Ecological Applications). EML is implemented as a
series of XML document types that can by used in a modular and extensible
manner to document ecological data. Each EML module is designed to describe
one logical part of the total metadata that should be included with any
ecological dataset.



FGDC CSDGM
~~~~~~~~~~

- http://www.fgdc.gov/metadata/geospatial-metadata-standards

The Content Standard for Digital Geospatial Metadata (CSDGM), Vers. 2
(FGDC-STD-001-1998) is the US Federal Metadata standard. The Federal
Geographic Data Committee originally adopted the CSDGM in 1994 and revised it
in 1998. According to Executive Order 12096 all Federal agencies are ordered
to use this standard to document geospatial data created as of January, 1995.
The standard is often referred to as the FGDC Metadata Standard and has been
implemented beyond the federal level with State and local governments adopting
the metadata standard as well.

::

  -bio
  (word document available for descriptions, Matt has XSD of FGDCbio)
  (excel spreadsheet listing mapping,
   xslt: EML->FGDC (lossy), FGDC->EML)
  (mapping available for EML -> DC (Duane))



GCMD DIF
~~~~~~~~

Directory Interchange Format

- http://gcmd.nasa.gov/User/difguide/difman.html

The DIF does not compete with other metadata standards. It is simply the
"container" for the metadata elements that are maintained in the IDN database,
where validation for mandatory fields, keywords, personnel, etc. takes place.

The DIF is used to create directory entries which describe a group of data. A
DIF consists of a collection of fields which detail specific information about
the data. Eight fields are required in the DIF; the others expand upon and
clarify the information. Some of the fields are text fields, others require
the use of controlled keywords (sometimes known as "valids").

The DIF allows users of data to understand the contents of a data set and
contains those fields which are necessary for users to decide whether a
particular data set would be useful for their needs.

- Mapping to DC available at http://gcmd.nasa.gov/Aboutus/standards/dublin_to_dif.html


ISO 19137
~~~~~~~~~

http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=32555

ISO 19137:2007 defines a core profile of the spatial schema specified in ISO
19107 that specifies, in accordance with ISO 19106, a minimal set of geometric
elements necessary for the efficient creation of application schemata.

It supports many of the spatial data formats and description languages already
developed and in broad use within several nations or liaison organizations.



NEXML
~~~~~

http://nexml.org

The NEXUS file format is a commonly used format for phylogenetic data.
Unfortunately, over time, the format has become overloaded - which has caused
various problems. Meanwhile, new technologies around the XML standard have
emerged. These technologies have the potential to greatly simplify, and
improve robustness, in the processing of phylogenetic data:



Water ML
~~~~~~~~

http://his.cuahsi.org/wofws.html

Web services are computer applications that interact with and exchange
information with other applications over the internet. The CUAHSI-HIS uses a
family of web services, called WaterOneFlow, that have been developed as a
standard mechanism for the TRANSFER of hydrologic data between hydrologic data
servers (databases) and users. Web services streamline the often time
consuming tasks of extracting data from a data source, transforming it into a
usable format and loading it in to an analysis environment. Web services
format the data as XML and the specific variety of XML that is generated by
the WaterOneFlow web services is known as CUAHSI WaterML. The specifics of
WaterML are documented in the OGC™ Discussion Paper, CUAHSI WaterMLWeb
services are computer applications that interact with and exchange information
with other applications over the internet. The CUAHSI-HIS uses a family of web
services, called WaterOneFlow, that have been developed as a standard
mechanism for the TRANSFER of hydrologic data between hydrologic data servers
(databases) and users. Web services streamline the often time consuming tasks
of extracting data from a data source, transforming it into a usable format
and loading it in to an analysis environment. Web services format the data as
XML and the specific variety of XML that is generated by the WaterOneFlow web
services is known as CUAHSI WaterML. The specifics of WaterML are documented
in the OGC™ Discussion Paper, CUAHSI WaterML.



Genbank internal format
~~~~~~~~~~~~~~~~~~~~~~~

http://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html



ISO 19115
~~~~~~~~~

- http://en.wikipedia.org/wiki/ISO_19115

ISO 19115 "Geographic Information - Metadata" is a standard of the
International Organization for Standardization (ISO). It is a component of the
series of ISO 191xx standards for Geospatial metadata. ISO 19115 defines how
to describe geographical information and associated services, including
contents, spatial-temporal purchases, data quality, access and rights to use.
The standard defines more than 400 meta data elements, 20 core elements.

- NA profile
- bio profile
- marine community metadata profile
- WMO profile



Dryad Application Profile
~~~~~~~~~~~~~~~~~~~~~~~~~

https://www.nescent.org/wg_dryad/Metadata_Profile

The Dryad metadata team has developed a metadata application profile based on
the Dublin Core Metadata Initiative Abstract Model (DCAM) following the Dublin
Core guidelines for application profiles. The Dryad application profile is
being developed to conform Dublin Core Singapore Framework, a framework
aligning with Semantic Web development and deployment.



ADN
~~~

- http://www.dlese.org/Metadata/adn-item/

The purpose of the ADN (ADEPT/DLESE/NASA) metadata framework is to describe
resources typically used in learning environments (e.g. classroom activities,
lesson plans, modules, visualizations, some datasets) for discovery by the
Earth system education community.



GML Profiles
~~~~~~~~~~~~

- http://en.wikipedia.org/wiki/Geography_Markup_Language#Profile

GML profiles are logical restrictions to GML, and may be expressed by a
document, an XML schema or both.



NetCDF-CF-OPeNDAP
~~~~~~~~~~~~~~~~~

- http://opendap.org/

- http://www.oceanobs09.net/work/cwp_proposals/docs/100_Hankin_StandardsOceanDataInteroperability_CWPprop.doc




DDI
~~~

- Data Documentation Initiative 

- http://www.ddialliance.org/

"The Data Documentation Initiative is an international effort to establish a
standard for technical documentation describing social science data. A
membership-based Alliance is developing the DDI specification, which is
written in XML."



MAGE
~~~~

- MicroArray and Gene Expression

- http://www.mged.org/Workgroups/MAGE/mage.html

"The group aims to provide a standard for the representation of microarray
expression data that would facilitate the exchange of microarray information
between different data systems."



ESML
~~~~

- Earth Science Markup Language

- http://esml.itsc.uah.edu/

"Earth science data is archived and distributed in many different formats
varying from character format, packed binary, "standard" scientific formats to
self-describing formats. This heterogeneity results in data-application
interoperability problems for scientific tools. The Earth Science Markup
Language (ESML) is an elegant solution to this problem. ESML is an interchange
technology that enables data (both structural and semantic) interoperability
with applications without enforcing a standard format within the Earth science
community."

  


CSR
~~~

- Cruise Summary Report

- http://www.oceanteacher.org/oceanteacher/index.php/Cruise_Summary_Report_%28CSR%29

- Oceanographic cruise data standard

The Cruise Summary Report (CSR), previously known as ROSCOP (Report of
Observations/Samples Collected by Oceanographic Programmes), is an established
international standard designed to gather information about oceanographic
data. ROSCOP was conceived in the late 1960s by the IOC to provide a low level
inventory for tracking oceanographic data collected on Research Vessels.

The ROSCOP form was extensively revised in 1990, and was re-named CSR (Cruise
Summary Report), but the name ROSCOP still persists with many marine
scientists. Most marine disciplines are represented in ROSCOP, including
physical, chemical, and biological oceanography, fisheries, marine
contamination/pollution, and marine meteorology. The ROSCOP database is
maintained by ICES



.. raw:: latex

   \newpage

Extracted Search Attributes
---------------------------

Data that exists within the DataONE system is always accompanied by science
metadata in one of the supported metadata schemes (e.g. Dublin Core, EML, or
another supported scheme) and expressed in one of the supported formats (e.g.
XML, RDF-XML). The science metadata is also replicated with the data (where
the Member Node (MN) supports the format and scheme) and additional copies are
replicated across the Coordinating Nodes (CNs). The science metadata is
parsed by the CNs to extract information for verification the content meets
minimal metadata content and consistency requirements, and to support search
operations.


Essential Elements
~~~~~~~~~~~~~~~~~~

- PI / Author

  - name authority service is desired for some control over names appearing in metadata

  - but for search, advantages to keep simple text representation

  - goal of gradual increase in specificity


- Keyword (uncontrolled keywords)

- Key concept -key concepts drawn from a set of ontologies

  - term

  - namespace

- Spatial bounding box (largest bounding rectangle)

- Spatial window (series of spatial envelopes representative of the spatial locations of where the data is collected from / relevant to.).

  - Spatial features (points, bounding boxes, polygons)

  - centroid

  - bounding box

  - polygon

  - ( not largest extent )

  - ( need to resolve the semantics of the bounding box search - e.g. if centroids are recorded but fall outside of bounding box search )


- Named places
 
  - term 

  - type 

  - context (Columbus OH, Columbus GA)

  - namespace of gazeteer  


- Temporal window

  - Relative terms (e.g. paleo periods) need to be supported

  - Date ranges

  - Temporal coverage of the data set  (e.g. searches - during, before, after)
  
- Full text search / Text search on abstract


Desirable Elements
~~~~~~~~~~~~~~~~~~
  
- Title (2)

- Type of data (format) (2)
  
  - original data

  - summarized versions

  - method used for processing (to generate summary, or original data)

  - Resource type (spatial, models, observations, web service, ...)


- Scientific variables (from a controlled vocabulary) (1)

- Domain of data (physics, environmental, ...) (1)

- Biological taxonomic extents (1)

- Search by publication (1)


Some Others
~~~~~~~~~~~

- Generator of data (instrument, application)

- Related data (data sets, publications)

- Quality / level of curation

- Organizations involved in study

- Size of data (bytes)

- Number / location of replicas 

- Dimensionality of data 

- Units of measure (for sci variables)

- Identifier (GUID)

- Temporal coverage, low priority

  - (publication date )

  - creation date

  - last modified date

- Permissions on objects (e.g. available to read by user)



Mutability
----------

Data and science metadata are immutable for the first version of the
DataONE system. As such, resolving the identifiers assigned to the data or the
science metadata will always resolve to the same stream of bytes.

.. todo::
   Byte stream equivalence of replicated science metadata would
   require that MNs record an exact copy of the metadata document received
   during replication operations in addition to the content that would be
   extracted and stored as part of the normal (existing) operations of a MN.
   Is this a reasonable requirement for MNs? Since MNs are required to store a
   copy of data, it seems reasonable to assume a copy of the metadata can be
   stored as well.


The DataONE :func:`CN_crud.update` method will fail if attempting to modify an
instance of science data. 

Deletion of content is only available to DataONE administrators (perhaps a
curator role is required?).

.. todo::
   Define the procedures for content deletion - who is responsible,
   procedures for contacting authors, timeliness of response.


Data Endianness
---------------

The data component of a D1 package is opaque to the D1 system (though this may
change in the future), and so the endianness of the content does not affect
operations except that it must be preserved. However, processing modules may
utilize content from D1 and may be sensitive to the byte ordering of content.
As such, the endianness of the data content should be recorded in the user
supplied metadata (the science metadata), and where not present SHOULD be
assumed to be least significant byte first (LSB, or small-endian).


.. todo::
   Describe how endianness is specified in various science metadata
   formats.


Longevity
---------

An original copy of the data is maintained for a long as practicable (ideally,
the original content is never deleted). Derived copies of content, such as
might occur when a new copy of a data object is created to migrate to a
different binary format (e.g. an Excel 1.0 spreadsheet translated to Open
Document Format) always create a new data object that will be noted as an
annotation recorded in the system metadata of the data package.


Metadata Character Encoding
---------------------------

All metadata, including the science metadata and D1 package metadata MUST
be encoded in the UTF-8 encoding. The DataONE :func:`CN_crud.create` and
:func:`CN_crud.update` methods always expect UTF-8 encoded information, and so
content that contains characters outside of the ASCII character set should be
converted to UTF-8 through an appropriate mechanism before adding to DataONE.


Metadata Minimal Content
------------------------

Experiment metadata MUST contain a minimal set of fields to be accepted by the
DataONE system.

.. todo::
   List and define the minimal set of fields with examples. A starting
   point would be the union of the required search properties and the
   information required for accurate citation.

